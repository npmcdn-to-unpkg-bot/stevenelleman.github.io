/*content */

var blog_isis = "In the wake of the tragedy in Paris I have seen numerous posts expressing how the extremists who perpetrated these killings went against the teachings of Islam and were not <q>true</q> Muslims. In the wake of the hateful things that the Westboro Baptist Church does, American Christians make it absolutely clear how the Westboro practitioners are not real Christians. By definition Islamic means that the Quran is the emphasized sacred text. ISIS and Islamic extremists use the Quran. Christianity means that the Bible is the emphasized sacred text and the Westboro Baptist Church emphasizes the Bible. ISIS is Islamic, and the Westboro Baptist Church is Christian. Is this to say ISIS REPRESENTS Islam? Of course not - there are 1.3 billion Muslims in the world, and ISIS represents an extremely small fraction of Muslims. Is this to say the Westboro Baptist Church REPRESENTS Christianity? Of course not - Christianity encompasses numerous sects. Both ISIS and the Westboro Baptist Church represent extreme interpretations of the Quran and Bible respectively. To say ISIS is not Islamic is factually incorrect. Rather than attempting to cordon extremist groups off and rationalize how non-Islamic or non-Christian they are, we need to recognize that religion is in large part interpretation and that there are many many interpretations - most moderate but some extreme. This is more accurate and avoids fear-mongering and stereotyping - it recognizes that a particular religion does not inherently create extremists; there are extreme interpretations WITHIN ALL IDEOLOGIES (including atheism, for that matter). In our day and age what defines extremism is imposition of values, of violently impressing ones own values onto others. Being a moderate is simply respecting others to make their own choice. On the basis of this distinction Islamophobia describes a fear that can be applied to all ideologies, not just to one in particular.";

var blog_shootings = "My entire life I've heard men talk about something being <q>taken,</q> that they were <q>picked on</q> by others and the victim of some ambiguous assault on them. It was always white men expecting commiseration from other white men, and I was expected to chip in. As I grew up the pattern continued, comments loaded with self-pity directed at the same audience - an echo chamber for self-proclaimed victims, burdened by a shared but nameless experience. Following the recent Oregon shooting I began to connect these experiences with the fact that a consistent pattern in American school shootings is that the shooter is a white male. While the fallout of each shooting is a massive national argument over the status of guns, what never enters the argument is a much-needed discussion of the underlying motivation and how there is a definite pattern in these shootings. While guns are the means by which these tragedies unfold, the motivation for such acts exists with or without them; guns just enable the motivation to be expressed in an incredibly destructive way. The closest the argument gets to the question of motivation is proclaiming the shooter mentally ill. But mental illness is an excuse to dismiss the issue. There is certainly no way to understand this illness, we cannot change it, we can stop talking about it and go back to pretending there is absolutely no problem. Catastrophe requires a perfect alignment of probabilities; these shootings are no different. Guns are one factor, being a young white male seems to be another (at least in the shootings discussed by the media), and some kind of satisfaction from a hyper-violent blowout is another. What is a phenomena shared by white males that could account for overrepresentation in school shootings relative to population? Having family in the Southeast and having lived in Northeast and on the West Coast there is a shared sentiment among white men: something has been taken. But what has been taken? What has been taken from white men that they cannot describe themselves? Men have lost something. They have lost arbitrary authority - by traditional standards of masculinity they have been emasculated for a very simple reason: contraception. Before contraception was accessible and acceptable, if a man and a woman were in a relationship, the woman would be having children for much of her adult life. What this meant was that men were the default provider and society was set up around that expectation, confining women to the home whether or not they were capable of economic independence. Even if a man was a complete failure, if he had a wife and children that depended on him he had power stemming from necessity. It is in this context that chivalry existed - that men at any point could do whatever they wanted to women who were fundamentally vulnerable, but chose not to. The dragon that held the damsel in distress could be found within every man: arbitrary authority enabled terrible wrongs to be committed. However, the knight could also be found within every man: self-sacrifice for those depending on his authority was the positive reality of chivalry. Yes, men have lost something: the economic dependence of women. Contraception did much more than enable women to control pregnancy, it enabled them to control their own economic security. Women do not need men for survival any more. From this perspective is it surprising that the generation following the sexual revolution had unprecedented rates of divorce? Absolutely not. Men had not reacted to a fundamental shift in circumstances, but women could act: they could leave. This was the death knell of traditional views on masculinity, but it is so fundamentally obvious that nobody noticed - like an object that is so close to your face that you are unable to see it in focus without backing up a few steps. But people can feel it. Below the surface people know it. No wonder popular culture has become increasingly violent, increasingly masculine; it is to fill a conspicuous absence. The causality runs in the opposite direction - hyper-violent, hyper-sexualized and hyper-masculine media is a form of compensation, an attempt to move back to ideals that no longer fit contemporary circumstances. This popular culture communicates one thing to men: die for a cause and you're nobel, you're a hero, risk your life for a cause and you'll get the girl, you're a hero. Self-sacrifice stems from the same traditional view of masculinity - the man sacrifices for those dependent on him, for women and children. Self-sacrifice was the positive reality of male authority. This message belongs to a different time, appealing to antiquated ideals that we cling to more and more desperately. It is not coincidence that superheroes - essentially all male - are so engaging and ubiquitous: they reflect our ideals for both men and women (hence the absence of female superheroes). They offer catharsis for a sentiment of loss and expectations unfulfilled. They are the knights we so desperately want to be. No wonder why gun activists are up in arms - the gun is one of the last holdouts on masculine empowerment. Losing the gun is assenting to male impotence. No wonder there has been such intense male activism in the pro-life movement. The pro-life/pro-gun bloc in the 87%-white, 80%-male Congress is not unified by life; if it was the bloc would be pro-life/anti-gun. No, it is unified by male fear of dis-empowerment - losing control over women's bodies and empowerment through arms. Both stem from a sense of masculinity lost, and fear of losing more ground. No wonder this aggression is expressed through shootings, through the hyper-masculine. I belong to a generation of men who feel utterly impotent, unable to feel a sense of value through authority that in the past they could always find through the women who depended on them. And in a world in which the ratio of men to women was approximately one to one and women were not allowed to support themselves, that meant all men had authority - and a default target for externalizing their own insecurity. An incredibly pervasive theme in these shootings, occurring in almost every case, is an element of sexual frustration and female rejection. And in each case the sentiment of the shooter is the same - it's not fair, I didn't get what I deserved, something was taken. Rather than looking towards their own behavior for solutions they gravitate towards a far more appealing rationalization of events: I am the victim, but I'll show them. No wonder why each of these shootings involve a doctrine - the doctrine is a social justification for their own victimization, to guise their hyper-desperate murder-suicide blowout as a form of justified hyper-masculine self-sacrifice, absolving them of responsibility. In a society in which self-sacrifice has lost its necessary context, it exists eerily close to suicide. The public doctrine is for the shooter - it provides the necessary pretext, it outlines the wrongs committed against them and the <q>fair</q> recourse that they chose. They are the perverse hero in the tale of their own victimization, and it is a very tall tale. School shootings are one symptom of a male identity crisis. As a man, I have a message to other men in this country: yes, something has been lost. We should be grateful it has. The positive reality of self-sacrifice and the negative reality of abuse and chauvinism followed from the inherent premise of male power and female vulnerability; a premise that was fundamentally undone by contraception. We must hold ourselves to a different standard, one in which we have to respect others properly. We are responsible for creating this new standard, rather than clinging to antiquated ideals unfit for our times. Are we victims? Yes, by our own hand. By subjecting ourselves to an unfair and unfit standard we have wronged ourselves. We will never be able to live up to those standards. They belong to a different time. We have a responsibility to ourselves to follow a standard for our times. Let us turn a collective tragedy into an opportunity for the ultimate atonement: change. I know where my change is starting.";

var observations = "<p> In different social settings we have different ways of presenting ourselves, often to fit into the expectations of those around us. We do this so that they like us, one of the primary ways of deriving a sense of self-worth is through the approbation of others. Here are some tips for maximizing approbation while not alienating those around us. 
<br><br>
1. Don't make assumptions.
<br><br>
Making assumptions, especially about someone's ethnic or cultural origin, is one of the riskiest ways of starting off with someone. We often make this mistake because we want to impress others, but honestly the risk isn't worth it. Making a mistake is usually regarded as highly offensive and guessing correctly offers very few benefits. While asking certain questions may seem invasive or embarrassing, understanding when to give up and ask is very important when working with others. 
<br><br>
2. Make others feel important.
<br><br>
We strive for the appreciation of others. This is why we all wear masks of half-truths, masks that are adapted according to what we think others expect and want of us. While we change our presentation for others, often the other person is so involved in the same process that nobody gives the appreciation that everyone desperately wants. Wearing masks is a strange mix of self-sacrificing and egocentric; we are willing to change major aspects of ourselves to feel valuable. And when the appreciation we expect doesn't come, we wear the mask more and more desperately, willing to sacrifice more and more aspects of ourselves. This cycle can become destructive, very very easily. 
<br><br>
I prefer the opposite process, one that creates a win-win scenario. If you genuinely appreciate something that another person does, always say it. Always say nice, true things. There is no down-side. And this is exactly what others want; they just want to feel appreciated. 
<br><br>
Recently I went to Asha's Teahouse in Berkeley and I thanked the baristo for bringing joy to people through fabulous tea. After this token of appreciation, his face completely transformed. He went from tired to happy, really really happy, in a few seconds. He immediately replied <q>You're the guy!</q> I asked him what he meant. He then told me that I had done the same thing before - I had, five months before, and he remembered it. Appreciation is powerful, because it is what people so desperately want (especially in the service industry). 
<br><br>
While this process can be very powerful, you also have to watch out for negative expectations. A good example are gender expectations. Men are expected to pursue, women are expected to be pursued. It's stupid but it is the expectation. What this means is that there are opposite biases - guys being nice to women are suspected of ulterior motive (it's fair enough, too), and women being nice to men are seen as teases. When making someone of the opposite gender important, understanding this bias becomes quite important. Very few people actually appreciate others, so when someone does others are initially suspicious. 
<br><br>
In other situations the bias can be used for your benefit. For instance, in environments with a hierarchy perceived inferiors are typically treated like crap by perceived superiors. Superiors who do this not only are massively insecure but are missing a chance to win major brownie points. It's my impression that these superiors don't actually feel superior so they have to beat up underlings to prove their authority - prove it to themselves. A superior who knows they are an authority does not need to treat their underlings like crap - it fundamentally doesn't help anyone. But as this is the expectation, if a perceived superior is decent to perceived inferiors, that decency is amplified by the negative expectation. I have had so many amazing conversation and experiences with cab/uber drivers, homeless folks, and service workers because I treated them like equals in a situation in which they expected to be treated like inferiors. 
<br><br>
3. Start with commonalities, work to differences.
<br><br>
Human interactions can be seen in terms of energy barriers. We only meet new people if the energy barrier is lowered by what we can get from the interaction - the person may look interesting, they may be beautiful, they may have a nice smile. These all help lower the barrier. In conversations the best way of lowering the barrier is by targeting commonalities. By finding commonalities you make the other person more invested in the conversation. Another major barrier is lack of trust, when you establish commonalities and establish more credibility you can then move to away from commonalities to differences. Differences require more tact because there is potential for confrontation. So when I discuss differences I'm usually prepared to fall on my sword - I would prefer to keep a relationship intact than burn a bridge. 
<br><br>
4. Actually listen. 
<br><br>
Super simple but when I meet someone several times and I can remember personal minutiae the other person really appreciates it, and are often shocked. We're often so focused on projecting that we miss what the other person is projecting. If you listen the other person can feel assured and appreciated. 
<br><br>
5. To have a friend, you have to be a friend.
<br><br>
Relationships are an exchange. Each person requires something from the situation, if they aren't they shouldn't be in the relationship. While there is a big focus on unconditional love, it is a silly concept, because it is a relationship that could be completely arbitrary and meaningless. Often what people label as unconditional love is completely conditional, the conditions are just so obvious that they blend into the background. But by striving for this false ideal, people invest too much energy in the arbitrary and the meaningless. Moreover, unconditional love begets unconditional hatred. Emphasis on the arbitrary bleeds into other emotions and enables a lot of nastiness. By thinking about a relationship as a reciprocal exchange (but in two sets of terms) the relationship remains meaningful - trust and love is earned through meaningful actions. Distrust is also earned and is not arbitrary. 
<br><br>
Trust and love are always vulnerable. Happiness is always vulnerable. There is always something valuable to lose. Many people fear loss more than they want to gain - they choose secure unhappiness over insecure happiness. For this reason, most people won't invest in being a friend first, they are waiting for the other person to move. Once you understand happiness is always insecure and accept it, it is pretty easy to be the friend first. So many people are just waiting to be met, but they require others to take the brunt of risk and be the friend first. Just do it. It's worth it. 
<br><br>
6. Smile.
<br><br>
Lower the energy barrier. That's it. 
<br><br>
7. There is no down-side of being polite. 
<br><br>
Some cultures require manners and politeness in conversation. In southeastern US, politeness is required for conversation. When southeastern folks go anywhere else in the country they are inhibited by the fact that they can only interact in such specific conditions. But if you understand this, being polite is appealing to everyone - for the folks that require it, they will immediately like you because you fit in their expectations. For the folks that don't require it, they will either be pleasantly surprised or slightly suspicious that you're sucking up. This also applies to smiling and being cheery - in Northern Europe and in the northeastern US people initially think these characteristics are fake. Once they are convinced it is real, these folks really appreciate it though. Happiness is like infectious energy, and when others people catch it, the energy is amplified. 
<br><br>
8. Respect boundaries. Never impose your own values onto others. 
<br><br>
The values you have are a product of your experiences. Others' values are a product of their experiences. Understand that there is a fundamental barrier between your perspective and others' perspectives because of this difference in experiences. Respect this boundary. When you impose your own values on others, you are not properly respecting the fact that the other person's values may be consistent with their experiences. Being aware of this boundary allows you to discuss very sensitive topics in a very comfortable way - if it is made clear that you respect others' perspectives and their body of experiences you will have a collaborative experience rather than an adversarial one.
<br><br>
9. Persuasion requires valuing the other side.
<br><br>
I think many Americans imagine persuasion as holding your adversary in a death-grip of self-righteousness until they've been throttled into seeing the truth. This interpretation is guaranteed to fail. Effective persuasion is being a necessary mirror for another person - understanding their argument to such a high degree that you can explain it and its flaws in their terms. I do not do the persuading - they persuade themselves - but I am the necessary messenger. To be the messenger requires valuing the other person's perspective over missionizing them. This is difficult, to understand someone else's perspective fully you first have to be completely open to the possibility that your views could be wrong. For this reason I invest my trust not in my specific views but in my meta-views (i.e. views about views). I value self-improvement. Self-improvement is a certain way of looking at the nature of my interpretations, that my current interpretations are flawed and that through a process of identifying failures I will improve. This meta-view enables me to be wrong: to be wrong is an opportunity to improve. Many Americans invest their sense of self-worth in a specific way of viewing an issue. Consequently they cannot take the risk to understand other interpretations - to fully understand, one must start with the humility that they could be wrong. Otherwise there will be ideological barriers that prevent them from understanding, barriers for ideological self-preservation. Being the messenger requires I understand their interpretation and their motivational structure (i.e. how they see their self-worth) so that I can present a counter-argument and a certain motivational structure for them to be motivated to be persuaded. If you present a reasonable counter-interpretation without motivation to be persuaded, they will simply reject your argument. You need to provide both. 
<br><br>
10. Emotions beget actions. Actions can also beget emotions. 
<br><br>
People are social animals and emotions are infectious. Happiness, sadness, and anxiety can all be passed to others. A big mistake a lot of folks make is not masking the fact they are sad or anxious. A lot of the time these folks are wallowing in the cheap gratification of self-pity and want others to either commiserate or care. For the most part, they won't.  They will either take advantage of you or avoid you like a leper. Both are bad. Both are highly risky and conflict with your objective. The way you solve your problem is by putting on a mask - be happy, be nice and others will be infected. And then you have a reason to be happy. Actions will beget complimentary emotions. 
<br><br>
11. Redraw barriers
<br><br>
When discussing very sensitive topics, redrawing barriers can reduce the chance of confrontation to zero. Confrontations occur when the one person gets defensive and thinks the other person is assaulting their views or their worth. A simple way of avoiding such feelings is to redraw the ideological barrier so that instead of it being between the two of you its around both of you: we are one team trying to figure something out. Confrontation becomes a collaboration. Much more effective. 
<br><br>
12. Eliminate filler words

<br><br>
<q>Um</q>, <q>like</q>, <q> you know? </q> eliminate these and many others from your vocabulary. It is better to say nothing than to fill space with useless language. Filler words will drop your perceived IQ by 15 points. Nobody wants this, least of all you. 
<br><br>
</p>";

var blog_ap = "<p> 
    (written in response to worrisome changes in Collegeboard's AP US history standards)
    <br><br>
    College Board has changed its standards for AP American History due to overwhelming conservative criticism. The criticism has particularly targeted the white supremacy and slavery aspects of the previous standards and individual states have gone out of their way to eliminate them wholly from their academic guidelines. As part of Texas' state standards <q>new textbooks won't mention the Ku Klux Klan or Jim Crow laws.</q> (http://thinkprogress.org/economy/2015/07/30/3686060/conservatives-get-major-win-fight-ap-history-classes/ ) 
<br><br>
This is absurd. By denying the crimes of the past one perpetuates them. Only by recognizing, understanding, and acting against such violations of human dignity, such as racism, can one break the cycle of culpability. By changing these standards to censor the past (and therefore the present), conservative <q>leaders</q> deny the next generation the ability to recognize and solve the problems we have inherited; they pass the burden on, onto victim and victimizer alike. 
<br><br>
Is this leadership? 
<br><br>
No. 
<br><br>
This is a father shoving an offspring's head in the sand in the name of patriotism, dooming it to the same moral asphyxiation that his own father subjected him to. It's traditionalism in its ugliest form: the old preventing the young from correcting the errors of the present. 
<br><br>
To my generation: let us recognize, let us understand, and let us act against such terrible errors, such terrible crimes. For those who would be made victims by our forefathers, by acting you regain your dignity in the esteem of society. For those who would be made victimizers by our forefathers, by acting you regain your dignity in your own esteem. 
<br><br>

To those who would prefer not to look at these problems: we live in a country in which everyone wants to be the "good guy," but sometimes by wanting it so much, we reject the facts that say otherwise; we defend the pretense over the real thing. To you I ask one question: which one do you want to be? The pretense or the real thing? 
         </p>";

var blog_college = "<p> 
     Throughout the country, examples of sexual assault and rape cases in colleges have been coming to light, demonstrating awful crimes within the student and administrative bodies. While the news has covered many individual cases, there has been comparatively little discussion about how such crimes can be countered. 
<br><br>
But by applying simple economic thought to the problem, an incredibly simple solution emerges. 
<br><br>
When it comes down to it, at the heart of this issue is sex, and in this little thought experiment, I am going to view sex as a commodity, in which women control the supply and men have the demand. While this is vastly oversimplified and not fully accurate (there is mutual supply and demand, women have demand for sex and men also offer the supply) it is very interesting to pursue the line of reasoning that follows from this general model. 
<br><br>
If one side controls all the supply and the other all the demand, the way the supplier can change the price of a good is simple: form a cartel. By forming a cartel, the supply of a good can be rigorously controlled and consequently the price can be manipulated. 
<br><br>
In this case, the commodity is sex and the price are the conditions of the <q>exchange</q> of the good: there is proper respect and consent before, during, and after sex. 
<br><br>
If, for instance, a majority of sororities formed a cartel with the joint agreement that they would refuse to attend parties at any fraternity that was not properly respectful, in the event of rape or sexual assault (or even lesser offenses) the supply of sex would be completely cut to the offending fraternity, and the the fraternity in question would have a very strong incentive to change their behavior and to punish the individual(s) who were acting out of line. 
<br><br>
Moreover, frats would have no other recourse than to change their behavior. While cases of sexual assault and rape are often murky because of lack of witnesses and Americans' strange perception of alcohol (drunkedness = not responsible), acts of sober intimidation are not. If a fraternity attempts to intimidate sorority members to return to their parties, it will back-fire and they could be faced with lawsuits. Also, if one assumes that most men in fraternities are properly respectful, there is a strong incentive for these issues to remain in-house; changing the behavior of a few nasty individuals is less costly than risking criminal records for attempted intimidation. Thus, frats would really be left with one option: sort out the bad members so that the entire frat can benefit from girls coming back to parties. 
<br><br>
Finally, this model would also benefit the frats that are respectful, especially in the beginning. In the beginning of such joint action, for every disrespectful frat that is banned, the more supply there will be for the respectful frats, further incentivizing good behavior. 
<br><br>
Viewed in these economic terms, women truly have all the power to force men to clean up their act, provided they form united fronts. 
<br><br>
While cartels and monopolies usually get a bad rap, this is a case in which they could enable positive social change.


     </p>";

var blog_racism = "<p>
    Last fall I was having a conversation with a friend and she said, <q>You know, people should be proud of their race, they should be proud.</q> What struck me was the false equivalency that this statement implied, that race and culture were causal, not associative. I immediately asked her, <q>but should not they be proud of their culture? I mean, why should anyone be proud of race? It is fairly arbitrary, but cultural identity? That is something to be proud of.</q> Initially she was skeptical, but then I explained that I was German by ethnicity, but I was certainly not German culturally, and was proud to be an American, not a German. (not to say there is anything wrong with Germans) And being ethnically German? Why would I proud of that? Did I earn it? Of course not, in some cosmic lottery I was born with certain characteristics. 
<br>
<br>
That evening I reflected on the conversation and I came to the conclusion that the false equivalency of race and culture unpinned racist thought. Objective factors, rooted in culture, serve as justification for discrimination on the basis of race. This justification is dependent on the assumption that there is causality between these factors. But when it comes down to it culture and ethnicity are tied to same source but are fundamentally associative, both are the product of long-term isolation. 

<br>
<br>
Culture is the accumulation of perspective, and when a society exists in relative isolation this body of perspective is un-augmented by other perspectives. Consequently it goes in its own unique direction and certain cultural characteristics are perpetuated. Similarly in relative isolation certain genetic factors are perpetuated due to the Founder's Effect; in a small community there is a convergence toward genetic homogeneity. Isolation consequently leads to unique culture and race. 

<br>
<br>
But when it comes down to it, culture is taught while race is inherited. Consequently these factors are associative, although for the majority of history that associativity has been quite accurate. We have become a connected world quite recently, in historical terms and certainly in biological terms. For most of history, really until the colonialism, race would indicate culture. But that indicator depended on isolation, a factor that is disappearing due to the change in communications and the increasing interdependence through trade. 

<br>
<br>
In the world today, there are plenty of counterexamples of this false causality: in this country of immigrants, we are Americans culturally despite coming from all regions of the globe and from a huge range of racial groups. 

<br><br>
One of the ways of de-legitimizing racism is breaking down the perceived chain of causality. What is legitimacy? It is proof. Without a logical basis, one can target an issue rationally, even if the issue is emotionally driven. Even emotionally driven issues need a superficial logical basis. And that superficial reasoning is that race and culture are causal. What is the emotional basis for racism? Inadequacy. 
<br><br>
The American morality is based on the ideal of absolute freedom. With freedom comes choice and with choice comes personal responsibility. This is why we lionize people like Steve Jobs while hating (or completely ignoring) the downtrodden: the Steve Jobs are self-made and are fully responsible for their success while the poor are fully responsible for their poverty. Moreover, this is why edge case examples of people who do not fit into the model are roundly rejected: mental illness does not fit into this model at all. While this basis of morality encourages excellence, it also perpetuates cyclical poverty and discrimination. Moreover, it encourages lazy reasoning. Americans all want to be the <q>good guy,</q> this is readily apparent in our films and in our mythology of superheroes and gunslingers. But due to the degree of personal responsibility in this country, it is often easier to apply lazy reasoning to one's actions to be the good guy than to critically analyze the full chain of causality only to find that you might be the bad guy. Consequently there is a negative incentive for critical reasoning engrained within our morality. This has contributed to the streak of anti-intellectualism in America, a streak that is also shielded by the base assumption of democracy: we are all equal, which means my ignorance is just as good as your intellectualism. 
<br><br>
But in a culture with such a great degree of personal responsibility and such individual pressure for excellence, those who feel insecure would be attracted to the sense of superiority that prejudice provides, a sense of superiority that is fundamentally arbitrary. Prejudice, however, is a false premise that superficially legitimizes itself: if I think blue people are bad, I will not hire them or let them into my schools, limiting their economic and educational opportunities. Consequently a disparity in education and wages will then create objective differences between me and blue people, the blue people will be poorer and have higher levels of crime and incarceration, which superficially justifies the initial assumption that blue people are bad people. This is why changing racist attitudes is so difficult, especially in a culture in which it is necessary for a sense of personal adequacy; provided one follows the superficial reasoning that race and culture are causal, prejudice creates its own <q>proof.</q> 
<br><br>
Consequently targeting the <q>proof</q> will be insufficient, it is the superficial logic that creates its own proof. The logic must be the target, and must be broken down. And it is broken down by understanding the associativity of race and culture. 
<br><br>
What makes targeting this logic quite difficult is the fact that both perceived victims and victimizers appear to believe it. In comedy, why is it is only acceptable for a person within a specific racial community to make fun of their own racial community? A white person who makes fun of an Asian American is a racist, but an Asian American making fun of their community is acceptable. This holds true with all <q>minority</q> groups in the US, there are tacit racial boundaries. The reason there are racial boundaries is because of the false causality of race and culture. If I do not belong to a racial community, I cannot possibility understand their culture. In a sense, I have no racial ethos, that is only gained by having the same race. 
<br><br>
This also explains why there is a vastly different interpretation of the <q>N-word</q> based on who says it. Why is it acceptable for an African American to use a term that denotes a long history of abuse and racism? It is exactly because it indicates a shared experience and a shared victimization of African Americans. Race may motivate those common conditions and experiences, but what unifies people is not race itself, it is the profound perspective and culture that is shared. But this false causality is why ex-NAACP leader Rachel Dolezal pretended to be black. While she identified with African American culture, she would not have racial ethos if she was not black. But could she identify with that culture? Does someone have to be a particular race to fight for the advancement of all colored people? If the end goal of the organization is have a world in which colored people are treated with the same dignity and respect as white people, then the distinction could be self-defeating. (http://www.cnn.com/2015/06/16/us/washington-rachel-dolezal-naacp/). Her credibility was dependent in part on her race. Thus this misconception is shared by both perceived victims and victimizers alike, perpetuating the false logic of racism. 
<br><br>
There is an irony to this because <q>white</q> is actually a conglomeration of different European ethnicities, and of different European minority groups. While there used to be racial boundaries between these European ethnicities, even to a violent degree, they eventually became non-issues. This is why making fun of whites is a non-issue, because nobody gives a shit anymore. Using history as a guide (after all, history is the human data set) and looking at the development of the concept of <q>white,</q> becoming a <q>post-racial society</q> requires race to become a non-issue, but not culture. There are still many Irish-American communities that are proud of their culture. There are still Little Italy sections in many American cities that celebrate Italian culture. There are entire holidays that celebrate these individual cultures, which people outside of that specific racial community can still enjoy. Culture is still celebrated, but race has become a non-issue. Non-Irish can learn Irish Step-Dancing and have a great time on St. Patrick's Day. The false causality has been broken down, and people get over arbitrary racial differences, while celebrating objective cultural differences. This is certainly not to say the whites are some paragon of good, but simply looking at American history and the consistent racism against every new way of immigrants, <q>white</q> is a step in the right direction, with the end-goal of <q>human</q> being the only meaningful racial term. 
<br><br>
Breaking down the logic would logically lead to racism splitting into racism and culturalism, the former being arbitrary and the latter being objective. If I criticize the American perception of freedom and its relationship with cyclical poverty, it is fair game, because attitudes and ideology inform actions and actions create circumstances (which then perpetuate attitudes somehow). While some people might accuse me of being un-American, I would simply say that I love this country enough to seek to improve it, and critical thought and criticism are necessary for self-improvement. 
<br><br>
Culturalism leads to its own controversies though. It would make rational debate over religion fair game, which would especially offend Christians, Muslims, and Jews (it seems like the monotheistic religions have the <q>hardest</q> sense of reality and truth, polytheism like Hinduism is a lot more fluid and enables broader interpretation). This may be a reason that culturalism has not emerged yet, because the American people are still quite religious. 
<br><br>
How can the American morality be changed to encourage more rigorous reasoning? I believe it can be by changing the definition of freedom slightly: in the absence of information I am not free, in fact I have no choice. Imagine being born without any sensory information at all. In those conditions how can one act? How can I effect change on circumstances? I cannot. If I have one piece of information how I respond to a situation is limited to that information. Consequently the more information I have and the more rigorously I understand a situation the more choice I have and the more freedom I have. Consequently knowledge enables freedom, and freedom enables a positive sense of self worth. Conversely knowingly remaining ignorant is a rejection of one's own right to a life and to one's own freedom. Only those without intrinsic human worth would reject their own freedom. What this shift requires is moving away from a nearly absolute sense of freedom we currently hold as truth. This sense of absolute freedom can already be logically toppled: on a slightly silly note the fact I cannot transform into an elephant right now is clear proof that I am not absolutely free. 
<br><br>
What follows from this is a probabilistic view of freedom: in every frame of time I have a limited number of potential actions I can take; I cannot turn into an elephant. Responsibility follows from choice, and I should only be responsible for the range of choices that are left for me. This view of freedom encompasses more <q>cases</q> than our current view on freedom does. Our current view of freedom does not account for racism, mental health, or cyclical poverty and incarcerations. In fact, it turns a blind eye to them, in each case one's <q>will-power</q> (or lack thereof) is to blame. 
<br><br>
With a more probabilistic view of freedom, racism and the constraints it imposes on one's choices are taken into account, as are the other aforementioned conditions. What is currently lacking is data, the raw data necessary for a probabilistic view of freedom to be feasible, data that is increasingly accessible in large quantities every day. 
<br><br>
While the American ideal of freedom seeks a fully singular individual, solely responsible for their own conditions and what they make of themselves, this ideal will never, ever be a reality. Consequently, we must depart from it, in order to find a system of thought and morality that is able to structure our behavior more effectively in the situations that the current system cannot account for. 
<br><br>
While this is my take on an issue, it could (and probably is) flawed to a certain degree. Criticism is necessary for self-improvement and is always welcome. selleman@berkeley.edu 
    
   


     </p>";
var blog_litmus = "<p> 
	It just occurred to me that how one perceives compliments indicates a tremendous amount about how they see the source of self-worth. When I see men complimenting women often the compliment is a kind of debt to be repaid. The only way such a debt would ever exist is in a system in which self-worth was determined by others. In that system, a compliment would be a kind of debt, because the giver has  <q>added</q> to the self worth of the receiver. 
<br><br>
This is why many men recoil when women not only accept their compliment, but agree with it: by agreeing with it, the receiver has rejected the obligation that the giver initially expected (and undoubtedly would try to leverage later on). While the giver often labels this as immodesty, this is an accusation used to regain the upper-hand in the power dynamic (essentially by shaming the woman). 
<br><br>
On the other hand, when I see compliments as a form of gratitude, the intent of the compliment is not to define the worth of the other but to express appreciation. Gratitude or appreciation is one-directional, defining only the receiver in the eyes of the giver, and whatever effect it has on the self-respect of the receiver is defined by the receiver. In these cases I have never seen the giver recoil when their compliment is accepted by the receiver (simply because the giver does not expect a debt with the compliment). 
<br><br>
I think this is a very effective and simple test for women to use to gauge men: if the man recoils when a woman agrees with a compliment, one way or another the man sees your worth as dependent on their opinion, if they do not, the compliment was made out of gratitude and they did not expect their opinion to affect your own self-respect. 
<br><br>
While I am using an example about gender dynamics, I have seen the exact same thing with white people complimenting minorities (in the US) and able-bodied people complimenting those with handicaps. In the Autobiography of Malcolm X, there were striking examples of drunk whites wildly complimenting African Americans. In the text Malcolm X found these cases quite strange; he describes the whites as feeling <q>magnanimous</q>. Using this interpretation however, it makes sense: the whites felt magnanimous because they were <q>giving</q> self-worth to the African Americans <q>for free</q>. They saw the value of the African Americans as dependent on the opinion of whites because whites were supposedly superior. 
<br><br>
What all three of these relationships have in common is that the power dynamic is dependent on affecting the self-perception of the receiver of the compliment. In Black Skin, White Masks by Frantz Fanon, he said that slavery is actually a system of self-perception; the only way that a huge enslaved majority can be controlled by a tiny ruling majority is if they have been taught to agree with with the minority about their own worth. 
<br><br>
So if you are ever complimented, here is my advice: own up to it, own up to your own worth and your own awesomeness. It will do two things: 1.) It will indicate if the giver of the compliment believes they can define your worth and 2.) By defining your own self-worth, you will prevent others from arbitrarily (on the basis of race, gender, sex, etc.) having influence/power over you. 
<br><br>
While many people would probably see this advice as inappropriate, how is it actually? If I compliment a friend for being awesome why is it inappropriate for them to recognize independently what they rightfully deserve? If I treat people with the dignity and respect they deserve, why am I unable to recognize it along with the self-respect associatied with being a decent human being? I believe our conception of immodesty comes from a catch-22 in Christianity (especially the more Puritanic interpretations): if you are morally irresponsible, you have to recognize your sin, and if you are morally responsible you cannot recognize it because you would then be proud, and like Lucifer would be struck down. Thus self-respect becomes a form of pride, and pride begets immodesty. 
<br><br>
While this is my take on an issue, it could (and probably is) flawed to a certain degree. Emails are appreciated and criticism is always welcome! selleman@berkeley.edu

     </p>";

var blog_kant = "<p> (written as a forum question for my algorithms and databases course)
    <br><br>
I was reading over the last discussion about concurrency and the relationship between processors and memory and it seems to have quite a bit in common with Kant's ideas on transcendental idealism. Kant thought that the human mind was dependent on intuitions and concepts for it to be functional. According to Kant, intuitions are perceptions without definition while concepts are definitions without substance.  For intuitions to be meaningful, they need concepts and vice versa or both would be meaningless. Could a parallel be drawn to processing and memory? Memory definitely seems to have a parallel function with concepts. Memory stores definitions but those definitions seem to be meaningless without more context. The processor seems to apply the definitions stored in the memory onto other data that would be meaningless (to the computer) without the stored definitions. For instance, let's say there is a computer that specializes in voice-recognition. While it may have definitions stored in its memory (concepts), without inputted information (in this case, voice recordings, which would be equivalent to intuitions) that stored information would itself have no meaning - it's meaning is dependent on the nature of the inputted data. On the other hand, if a voice recording were uploaded to a regular computer without voice-recognition capabilities the recording would be meaningless as well. It almost seems like computation, like Kant's idea of the mind, is dependent on concepts and intuitions (or at least equivalents to them). 

While I may be forcing this parallel I think there is an element of truth to it. 
    
         </p>";
var blog_self = "<p> 
    
    <q>Give me a place to stand, and I will move the earth.</q>The paradox of this statement is the heart of Anthropology: by evaluating meaning through meaning there can never be a solid place to stand. To make a fully <q>objective</q> assessment, <q>to move the earth</q> in an absolute sense, is impossible; the only ground to stand on is the earth and any movement marks a relation. In anthropology the self and the other constitute the points in this relation, any judgment made by one on the other is equally descriptive of both, elucidating through contrast. As such, the best assessments in anthropology are the ones that come with open admission of one's own premise, one's own basis for thought, as much as is possible to discern. 
    <br><br>
The basis of science, and for that matter empiricism, is the premise that the mind exists within a larger reality and that that reality has a kind of continuity expressible by laws. This base assumption in and of itself marks a relation between the self and the external universe; sensory information is a reflection of reality, and the pursuit of <q>truth</q> is a pursuit for laws that are most consistent with experience and therefore reality. The relationship of the self and reality, and its counterpart in other cultures, is one of the most foundational cultural premises because it situates all other information relative to it. Imbedded within this relation is the nature of the individual (which may not and is often not individuated) and of reality. The changing nature of this relation elucidates the transitioning modes of human culture, from polytheism to monotheism to science, and offers a viewpoint where temporal continuity of human thought is evident. In order to describe this transition, abstraction becomes necessary at the expense of absolute accuracy. As in Mauss' <q>The Concept of the Person,</q> to survey so many different cultures, simplification is necessary for any measure of clarity. <br><br>
	Different forms of polytheism developed independently on every habitable continent in the world, with a remarkable degree of similarity in terms of the relationship between the individual and reality (remarkable degree considering their isolation, they are very different but they have very general similarities that are surprising). The similarities are seen through the conception of the individual. In Mauss' <q>The Category of the Person,</q> he follows the historical and cultural progression of the definition of the self. Among the earliest cultures, the self is not seen as a singular indivisible entity, but as an aggregate of ancestral power and family honor. The individual is not a singular, but a collective distilled into a mask of identity, into a familial name. In the Pueblo culture, <q>his title, his rank, his role, his survival and his reappearance on earth in one of his descendants endowed with the same status, forenames, titles, rights and functions</q> are part of the mask and of the familial name. In the Pueblo culture the name preserves the past, establishes credibility, defines one's role within the larger collective of the tribe and marks the reincarnation of the dead. Thus the name has a stabilizing function, enabling the continuity of tradition through the individual while holding the individual at a secondary position to their family; the individual is a vessel of the past. <br><br>
Like the Pueblo culture, the Zuni saw the <q>perpetuation of things and spirits [as] guaranteed by the perpetua[tion] of the names of individuals, of persons.</q> Moreover, by defeating an individual possessing a name of power, <q>his names, his goods, his obligations, his ancestors, his 'person', in the fullest sense of the word... are acquired</q> by the victor. The power endowed in names does not intrinsically belong to blood relatives, like a mask it can be possessed, it is an identity that can be won or lost. Definition of the self was not as a unique singular but an aggregate of identity, endowed with the spirits of the past and their powers.  <br><br>
In these two cultures, the self is not individuated, but a function of many identities. The mask or the name is where the individual and the spirit meet, and through it the individual has social agency. In the Pueblo and the Zuni cultures, spirits enable the individual to act within the community by defining their role and legitimizing their influence. By anchoring so much influence in spirits, the individual is defined on a mythological plane. Looking at the cosmological order of the Pueblo and Zuni from the perspective of science, one could even say that reality emanates from the mind; while science de-legitimizes the role of the imagination and hallucination and their perceived impact on reality, for these cultures imagination in the form of characterization of spirits is central to both social and natural life. What fundamentally enables this deep relationship between the mind and reality is the fact that the individual is not individuated. Through individuation, the barrier between the self and an external reality is created, preventing interaction between the mind and reality. <br><br>
In Kopenaw's <q>The Falling Sky,</q> spirits are also source of influence for the Yanomami of the Amazon; sickness was the result of <q>epidemic spirits</q> (114) such as the <q>jaguar spirits</q> (118) and the <q>ayokora cacique bird spirits</q> (124). The spirit, the <q>xapiri,</q> are the <q>yarori ancestors who turned into animals in the beginning of time.</q> (55) These spirits of ancestors are held responsible for disease and premature death, and without the xapiri shaman <q>the nostalgic ghosts would soon carry their relatives away with them and humans would die constantly, one after another, far too fast.</q> (128) Mysterious cause that produces death is the responsibility of past ancestors.  Human spirits that <q>metamorphosed into fly and vulture beings</q> (128) are the cause for effects like disease and death. Spirits endowed events with purpose, events that science would claim to be the product of coincidence and therefore without meaning, are situated in a cosmological order where there is very clear meaning. Spirits also enable agency. After a shaman killed a child <q>our evil spirits instantly fly to his house and devour a child... These aggressive xapiri are images of ne wari evil beings whom we only bring down for revenge.</q> (125, 126) The shaman acts through the spirits. <br><br>
Like the Zuni and Pueblo, the spirit is originally human in nature. The Yanomami cause is anthropomorphized and deified through the spirits, endowing otherwise ambiguous events with meaning and purpose. The way spirits are characterized and humanized shows how close the sense of self and reality is. While there is no discussion of Yanomami's conception of the self, the Yanomami assign ambiguous causality to humans, albeit deceased and deified ones. <q>Objective reality</q> and the mind overlap a great deal, and are even indivisible. The way the shaman interact with the spirits also elucidates the relationship between the self and reality. The fact that the shaman are <q>able to pull its [a spirit's] harmful things out of their bodies and throw them into the underworld</q> (114) show the tangible nature of the spirits. From a scientific perspective, shamanism seems to be a kind of psychological causality in which the mind, through imagination, impacts reality. The mind and reality are indivisible.<br><br>
In <q>Do Kamo</q> by Leenhardt, the Melanesians and their conception of <q>bao</q> which roughly translates into <q>god,</q> also indicate the nature of this relationship. Bao exists as a kind of passive intangibility, defined by a passive role in society,  <q>deprived of this costume [the body], he is nonreal; he no longer has a function in the society; he is a defuntus.</q> (33) Thus the insane man is honored with an <q>abundant mourning feast ... a social funeral ... he is no more than a defunctus, a disaffected member of society, a defunct man; but he is certainly not dead.</q> (33) Socially the insane man is a bao because his active role in society is at an end and he enters the passive phase of the bao. But this passive role is not without influence, the act of suicide becomes a <q>method of passing from the state of living to the state of bao â€“a state of invisibility and release from the body, where, liberated from the laws of this world, they can increase their strength tenfold.</q> (39) Thus the physical intangibility of the bao is actually a social one, in which the bao is not inhibited by the rules or responsibilities of society. 
<br><br>
The bao has three states: lucky, unlucky, and human (27). For both lucky and unlucky events the bao is assigned responsibility, much like the spirits of the Yanomamis. If someone has <q>a whitish blemish on his check ... a sign of leprosy... they will simply say that a bao has struck him. And there is no doubt that a god's invisible spear touched him there, because the god always carries minuscule spears with him.</q> (27) Thus an unlucky effect has been caused by the bao. The same goes for fortunate events. The power and influence that the bao wields comes from their very social absence, by being apart from society they are not constrained and can act with agency. Thus the bao is marked by <q>no support, no remains</q> that is why <q>there is no differentiation or distance between the corpse and the god.</q> (30) The body is but one constraint that is thrown off for greater influence. 
<br><br>
For the Melanesian the self is defined by a series of relations, to the totem, the god, the uterine groups, and the passions (90). The self exists in relation to the active social life as well, in contrast to the bao. Like the three previous cultures, the self is seen in terms of relations, stressing inter-dependence of the mind and reality.
<br><br>
In the cases of the Pueblo, Zuni, Yanomami, and Melanesians the relationship between the individual and reality is not marked by individuation, it is marked by indivisibility, to the extent that both social and natural cause is ascribed to spirits or bao. From a scientific point of view, it would appear that such natural phenomena are anthropomorphized and humanized because the mind interprets reality through itself and the ego. Consequently, understanding of the <q>external world</q> is marked by the human ego in the form of spirits. There is no internal realization that the nature of the mind differs from that of reality, they are viewed in the same terms, terms that are distinctly human.  This lack of division between the mind and self is consistent with the lack of individuation: to define the person as an individual is to already see a division between the self and reality. Individuation implies a barrier by its very definition. Furthermore, an individual defined through relations already realizes the inter-connectedness of the self and reality. Despite the differing origins of these four cases, they demonstrate the indivisible nature of the mind and reality and the polytheistic basis for the relationship.
<br><br>
Monotheistic religion, particularly in the form of Christianity, demonstrates a transition from the polytheistic basis for understanding the self and reality to the scientific basis. Between the aforementioned cases of polytheism and the advent of Christianity, more structured forms of polytheism, including Greek and Roman mythology as well as Hinduism, aggregated different kinds of cause into respective pantheons. Different areas were controlled by different deities, and like the spirits and bao, the deities are highly relatable in both their physical characteristics and actions. This changes in the monotheistic religions when the conception of God becomes increasingly abstract and impersonal. Aniconism is common in the monotheistic faiths, in Judaism and in Islam it is forbidden to depict Yahweh and Allah, and was also practiced in periods of Christian history. With monotheism came a shift in the sense of the individual, from a series of familial and spiritual relations to a single relation in Christianity, one's relationship with god as a <q>moral person.</q> 
<br><br>
As Mauss points out in <q>The Category of the Person</q> in his discussion of the Christian 'person' that in <q>Epistle to the Galatians, ch.3, v.28: 'You are, with respect to the one, neither Jew not Greek, slave nor freeman, male nor female, for you are all one person in Christ Jesus.'</q> (20) The concept of the Christian 'person' ruptures the relationship between religion, ethnicity, economics, and biology and the individual. The individual is truly singular, with the exception of their relationship with God. One's moral worth defines this relation, and through it the individual can earn their place in Heaven or Hell. By eliminating all other relations the individual's definition is no longer constrained by familial ties and ancestral spirits; the individual is cut off from others and from spirits. Instead the individual has free will and absolute agency with the understanding that sin will earn one a place in Hell. 
<br><br>
While the Bible tells the individual to act in a certain way towards others, it is with the purpose of being a moral person, not a reflection of specific social relations; social relations fall into the relationship between the individual and God. Viewing the simplification of the self in relation to God from the perspective of science, the psychological causality that is ubiquitous in polytheism essentially collapses. The individual has one outlet for such psychological causality: their place in the afterlife. Free will is a mixed bag, while it liberates one from social and ancestral relationships, it constrains the individual in the scope of the perceived psychological causality. Individuation is a barrier of definition, explicitly cutting off the self from psychological control of reality. Only after death does the individual exert that kind of influence. The individuated self marked a schism between efficient causality and psychological causality, free will expressed the individual's control of the former and virtual elimination of the latter. 
<br><br>
This schism also sets the stage for empiricism and science, with the assumptions of human control over efficient causality and nature as reflection of a single God. Together these form the basis of empiricism: the individual exists within a universe controlled by a single, consistent God. Many of the early scientists were monks and devout Christians, undoubtedly because the pursuit of consistency was also a theological undertaking for better understanding of what it means to live as a moral person; the pursuit of consistency follows from a single absolute deity. The transition from Christianity to Science required Nature to take the place of God and the individual's psychological causality in the form of the afterlife to be eliminated. Given the impersonal nature of God, the former was the first occur and is well documented. The latter followed from the former, as experimental findings increasingly contradicted the Bible and other sacred texts, there was a departure from the religion, either in the form of liberalizing it (i.e. understanding it as a figurative rather than a literal text) or agnosticism and atheism. Empiricism killed its own parent; once empiricism provided a more consistent model for an external reality while exposing the inconsistencies in Christianity, it marked the next legitimate model for reality. But if this essay shows anything, it is temporary nature of legitimacy. 
<br><br>
The transition from polytheism to science has been marked by the changing conception of the self and the relationship between the self and reality. For the Pueblo, Zuni, Yanomami, and Melanesians the self was not individuated and was instead marked by a series of social and spiritual relations that stressed the inter-dependence of the mind and reality and allowed for different forms of psychological causality. From this polytheistic basis to science the self becomes increasingly individuated, marking a simplification of relations, aggregating former relations into a single entity: the moral relationship between the individual and God. This transition marked a redefinition of human agency, limiting psychological causality to the afterlife while increasingly emphasizing human agency through efficient causality. Finally, the increased reliance on efficient causality and the assumption of a single, consistent God lead to the foundation of empiricism, initially as an exercise in theology, which eventually diverged from religion while exposing many of its inconsistencies, leading to liberalization of religious interpretation, complete departure from religion, and/or denial of science. The evolving relationship between the individual and reality is illustrative of the transition from polytheism to monotheism and to science, albeit in a very simplified model, elucidating the similarities and differences in current bases of human thought.  Above all else, the plurality of <q>truths</q> indicates an even larger truth: <q>legitimacy</q> of thought is always temporary and change is inevitable.
<br><br>
Works Cited
<br><br>
Kopenawa, Davi. <q>The Falling Sky.</q> â€” Davi Kopenawa, Bruce Albert. N.p., n.d. Web. 12 May 2015.
<br><br>
Leenhardt. <q>Do Kamo: Persons and Myth in the Melanesian World PDF Download.</q> Do Kamo: Persons and Myth in the Melanesian World Pdf Ebooks Free Download. N.p., n.d. Web. 12 May 2015.
<br><br>
Mauss, Marcel. <q>Idea of the Person - Mauss: The Person As <q>a Category Of The Human Mind</q></q> - Personhood, Names, Societies, and European. N.p., n.d. Web. 12 May 2015.
<br><br>

         </p>";
var blog_role = "<p> The Other is a form of cultural substitution in which societal pressures are outwardly directed as a form of catharsis. Myth, religion and science are all means of anthropomorphizing reality; transforming a reality devoid of purpose into one structured, like the human mind, by a nexus of meaning and purpose. Societal pressures and tension arise from contradictions between the ideal and the real, when cultural structures for reality are inconsistent with reality. Rather than directing attention towards the internal source of the tension, overtly casting doubt on the entire cultural framework that is built on faith, this tension is directed outwardly on the Other, on those that expose the inconsistencies. Thus the Other is the guilty exception to the rule, an exception that exposes the rule and its internal inconsistencies. 
    <br><br>
In Madness and Civilization, Foucault focuses on the European conception of the Other in the form of madness and malady during the Middle Ages and Enlightenment. Foucault discusses the role of the leper in the Middle Ages and Renaissance. The Medieval conception of leprosy was defined by <q>inverse exaltation</q>(Foucault, 6) in which the leper was treated as a sacred pariah, the sacred Other. For the leper there was <q>a strange reversibility that is the opposite of good works and prayer, they are saved by the hand that is not stretched out. The sinner who abandons the leper at his door opens his way to heaven.</q>(7) The leper's <q>existence was yet a constant manifestation of God, since it was a sign both of His anger and of His grace.</q>(6) God's anger and grace had a circular relationship; it was God's will that the leper be cursed, the greater the leper's suffering, the more satisfied God would be and the greater the eternal redemption.
<br><br>
	The relationship between madness and reason can more broadly be seen as the relationship between evil and good. Evil in the form of leprosy or madness was an act of God, but rather than demonstrating God's malevolence, the evil serves to define his benevolence. Thus extremes do not run infinitely from each other but into each other, defining each other through contrast. In a benevolent God's dominion, evil is resolved by defining his good, masking a paradox in the framework. Redemption was the mechanism through which evil becomes good, through which the spectrum becomes circular, but it is redemption dependent on God's omnipotence (Or Man's insignificance). As God is omnipotent he is responsible for the madness; dissemination of responsibility is top-down, emanating from God. Only because God is omnipotent and responsible for madness can redemption be an avenue to heaven for the leper. The leper is responsible for following God's command, not for his malady. The common language in which reason and madness could carry on a dialogue was a circular sense of interdependency, of good and evil and reason and madness, predicated on Mans' own insignificance. 
	<br><br>
	The leper and the madman exist at the cusp of madness and reason and evil and good, at the redemption point in this circular spectrum. At the point linking two extremes, they provide a form of cultural catharsis by masking the paradox of evil in a benevolent God's world. But the mask of one contradiction creates another paradox. If evil runs into good and madness into reason, would this not mean God plays both his own part and the part of the Devil? In this schema, Heaven and Hell would not only have equal footing but would be the same thing. Thus the individual would be responsible for following God's command and the Devil's command. Ignoring this paradox, Heaven is the carrot and Hell is the stick, motivating through both the pull of eternal redemption and the push of eternal damnation. In the Middle Ages the <q>twelve dualities</q> exactly outline this carrot-stick relationship: <q>the twelve dualities ... dispute the sovereignty of the human soul: Faith and Idolatry, Hope and Despair, Charity and Avarice, Chastity and Lust, Prudence and Folly, Patience and Anger, Gentleness and Harshness, Concord and Discord, Obedience and Rebellion, Perseverance and Inconstancy, Fortitude and Cowardice, Humility and Pride. (24)</q> Acknowledgement of this contradiction would lead to the collapse of the motivational structure created by this spectrum; the carrot and stick would become the same thing and cancel each other out. Thus the circular spectrum is self-defeating, provided the contradiction is noticed. 
	<br><br>
The Other provides catharsis for evil in a benevolent God's dominion and it is used to mask its very own paradox; a double substitution and double catharsis. <q>Self-attachment is the first sign of madness, but it is because man is attached to himself that he accepts error as truth, lies as reality, violence and ugliness as beauty and justice,</q>(26) thus madness exposes the truth of the spectrum's contradiction; the Madman is the exception that exposes the rule and its inconsistencies. But rather than acknowledging the truth in the madness, the cultural tension arising from this paradox feeds back into the cultural framework: the greater the Others' suffering the greater their redemption. The truth the madman exposes in the system can be justifiability dismissed; blame and punishment for internal inconsistencies can be externalized on the Other in the form of God's command for their malady. In fact, that would only guarantee the Others' place in heaven. Thus the Other exists as a kind of cultural Schrodinger's Cat, it simultaneously links the circular spectrum to solve one paradox only to be exiled and dismissed for the second. In a sense, the Other existed as a critical point in which cultural tension arising from two major paradoxes could be externalized and safely dissipated. Moreover, this critical point masked both paradoxes: evil in the form of madness existed in a benevolent God's world to define his benevolence but evil and good were not the same thing because that would be a quality of madness, one that must be dismissed for its own good. With these two models, each beset by its own paradox, the individual was simultaneously innocent for calamities of God's will (such as leprosy) but was responsible for carrying out God's will to get into Heaven. 
<br><br>
	In the Enlightenment <q>madness was shown, but on the other side of bars; if present, it was at a distance, under the eyes of a reason that no longer felt any relation to it and that would not compromise itself by too close a resemblance.</q> (70) While in Medieval Europe and the Renaissance <q>madness was present everywhere and mingled with every experience by its images or its dangers</q>(70) because of the inescapability of its circularity, madness in the classical period was isolated and segregated. <q>Confinement, prisons, dungeons, even tortures, engaged in a mute dialogue between reason and unreason... This dialogue itself was now disengaged; silence was absolute;</q>(262) in the Enlightenment, the circular relationship between madness and reason broke down, leaving a single spectrum of reason, of its presence and its absence. 
	<br><br>
	While the leper's malady was not his own responsibility, the madman <q>crosses the frontiers of bourgeois order of his own accord, and alienates himself outside the sacred limits of its ethic.</q>(58) The individual was now seen to be responsible for their madness, madness was given <q>a special sign: not that of sickness, but that of glorified scandal.</q>(70) The collapse of the circular spectrum changed the dynamic for individual responsibility. While in the Middle Ages and Renaissance there were certain reprieves on responsibility originating from Man's insignificance, there was a shift in Man's self-image in the Enlightenment. With the ascent of reason came the elevated status of humanity and a heightened sense of individual responsibility. Moreover, imbedded within this self-image was humanity and reason as completely distinct from animalism and madness. Morality is a kind of cultural self-image of humanity, denoting the ideal and non-ideal image of Man. The integration of reason and increased humanism tainted the makeup of good and evil; unreason and non-humanity approached evil. In fact, <q>for classicism, madness in its ultimate form is man in immediate relation to his animalism.</q>(74) Madness and animalism were grouped together, linked through the concept of the absence of reason and therefore the lack of humanity. What this all lead to was a single absolute spectrum of good and evil, reason and unreason, and human and animal in which individual responsibility through reason was paramount and existed with few forms of remission or reprieve. 
	<br><br>
	While in the Medieval period the Other occupied a simultaneously positive and negative position, in the Classical period the Other was a manifestation of the negative extreme of the moral spectrum, thus the Other epitomized madness and animalism. Foucault discusses the place of the mad in this schema. Insane asylums during the Classical period were <q>a kind of human stable ... a kind of cage ... [which] had gratings for floors, and did not rest on the ground but were raised about fifteen centimeters. Over these gratings was thrown a little straw upon which the madman lay, naked or nearly so, took his meals, and deposited his excrement.</q>(73) The mad are reduced to animals in their confinement, a reduction which <q>madness finds both its truth and its cure; when the madman has become a beast, this presence of the animal in man, a presence which constituted the scandal of madness, is eliminated: not that the animal is silenced, but man himself is abolished.</q>(76) As responsibility is predicated on humanity, by destroying the human, individual responsibility is removed and with it madness. In a sense, the Classical moral spectrum drops off on the side of the evil. Madness is defined on this spectrum, and dropping off the side of evil into nothingness; <q>he is both ultimate downfall and absolute innocence.</q>(82) Madness is defined in relation to reason and reason in relation to humanity. Outside this spectrum, madness is meaningless.
	<br><br>
	While the Classical model emphasizes individual responsibility, the individual is subject to a constant sense of guilt, a sense of passive fault from Original Sin. This contradiction of free agency and determinism produces tremendous personal tension; Humanity was <q>given</q> the divine right of free will and self-determination of moral worth but is unable to ever achieve perfection. In fact, to achieve perfection would be to approach the Devil; for Lucifer's perfection was undone by his recognition of his worth in the form of his pride. The Classical moral spectrum has an infinite sense of good but to approach it and recognize it would mean falling down the trapdoor of pride. Man was given a superficial form of self-determinism of moral worth; should they approach absolute good, they would be unable to recognize it lest they think themselves equal to God. But is this not a possibility enabled by free will? Free will meant that Man could be his own God, but by becoming his own God would destroy God. The fall of Lucifer in actuality is the story of perfection enabled by free will. Original Sin confines Man to a space of imperfection without the possibility of perfection, preventing his Fall from perfection by staining him but also assuring his Fall by holding him responsible for Adam's transgression. Unlike the Medieval model, in which the contradiction was masked by circular logic, in the Classical model, the ascent of reason exposed the harsh reality of this contradiction, elevating the tensions originating from the paradox.
	<br><br>
	Innocence provided a form of moral remission; but imbedded in the concept of innocence is paradox.  Superficially innocence appears to provide a means of resolving the contradiction of personal responsibility and guilt. A state of innocence restores Humanity back to the <q>innocence of Eden,</q> (56) before the Fall of Adam and Original Sin. But innocence originates from unreason. Only through unreason is Man not responsible for their evil but in this state of unreason there is no Man. Innocence is salvation through oblivion. And at this point of contradiction the Other resides, in a state of  <q>ultimate downfall and absolute innocence.</q>(82) 
	<br><br>
	While in the Medieval model, circularity enabled tension to dissipate, in the Classical model it fed into itself. The passive nature of guilt and the emphasis on responsibility not only imposes a burden, but a burden with no permanent means of resolution, producing continuous tension. Even the catharsis that the Other provides is temporary and feeds the tension. After discussing a case in which an insane man was chained for twelve years Foucault claims that when <q>practices reach this degree of violent intensity, it becomes clear that they are no longer inspired by the desire to punish nor by the duty to correct.</q>(72) It is because the degree of violence comes from another source: the closer the mad approach the animal, the less responsibility the sane have for their actions. As the madman is responsible for their madness, violence as a form of catharsis was justified on the grounds that <q>unchained animality could be mastered only by discipline and brutalizing;</q>(75) the greater the animality, the greater the fault of the Other, and the greater the acceptable punishment that could be dealt. This remained until absolute animality was achieved, at which point punishment was not a matter of fault but of pure cultural catharsis. The animal is innocent but also valueless; long after the madman had become the animal catharsis could still be gained through them. The catharsis however was quite temporary; punishment did not relieve the burden of Original Sin, nor did it mask paradox, it could relieve repressed tension through externalization on the basis of the prisoners' responsibility or their utter lack of moral worth. Ironically, oppression begot repression that begot oppression; the act of externalization was proof positive of one's inherent animality, proof that required even more repression. Because and despite this, <q>until the beginning of the nineteenth century ... madmen remained monstersâ€”that is, etymologically, beings or things to be shown,</q>(70) enabling temporary cultural catharsis. 
Fanon in Black Skin, White Masks discusses the construction of the Other in the context of colonialism following the Enlightenment. While Fanon is writing from the 1950s, nearly two hundred years after the Enlightenment, there is certain continuity in the European basis of morality. In the time between the Enlightenment and Fanon, the religious basis of this morality lived on in a new form: science. The Classical ideas of sin and virtue became invested in the biological and in race, as Fanon puts it, <q>sin is Negro as virtue is white.</q>(Fanon, 118) Moreover, the basis for Otherness, rather than using tradition as justification, put on a new guise, traditional Otherness was packaged in the form of the rational. While 
<br><br>
<q>the scientists had conceded that the Negro was a human being; in vivo and in vitro the Negro had been proved analogous to the white man: the same morphology, the same histology... like us he has his heart on the left side. But on certain points the white man remained intractable. Under no conditions did he wish any intimacy between the races, for it is a truism that <q>crossings between widely different races can lower the physical and mental level. . . . Until we have a more definite knowledge of the effect of race-crossings we shall certainly do best to avoid crossings between widely different races.</q>(99)
On a scientific basis of evidence and rationality the <q>truism that crossings between widely different races can lover the physical and mental level,</q> should be followed. In actuality, this <q>truism</q> is a recapitulation of traditional Otherness cast into an acceptable form, that of the rational. A more honest form of this Otherness can be seen in the <q>collective catharsis</q> of illustrated magazines for children. These magazines are <q>The magazines are put together by white men for little white men... in the magazines the Wolf, the Devil, the Evil Spirit, the Bad Man, the Savage are always symbolized by Negroes or Indians.</q>(124) These semi-mythological figures represent the same themes of Otherness found in the Classical spectrum, and these same themes feed the emotional content of the Otherness of the biological. The <q>Negro brought forth biology, penis, strong, athletic, potent, boxer, Joe Louis, Jesse Owens, Senegalese troops, savage, animal, devil, sin.</q>(144)  A phobia of Blackness is inculcated, for a <q>phobia of Negroes is to be afraid of the biological... [because] Negroes are animals.</q> (144) For Europeans, infused in this phobia of the biological is sexual desire and a fear of one's own animalism; Blackness represents (among other things) an externalization of White guilt originating from their own sexual repression. Fanon notes that <q>when a woman lives the fantasy of rape by a Negro, it is in some way the fulfillment of a private dream, of an inner wish. Accomplishing the phenomenon of turning against self, it is the woman who rapes herself. </q>(156) Thus the woman fantasizes the African because the African is the cultural substitution for the biological and sexual. As such, punishing the African is a form of externalization of tension coming from repression of biological urges, urges that are perceived as shameful. Just as the mad exposed the inconsistencies of past moral spectrums, the African has a cathartic role in their Otherness, resulting from the opposition of the biological reality and the moral ideology of the White colonialist. 
<br><br>
The <q>scapegoat complex</q>(160) of the Other, as Fanon puts it, consistently represents the internal conflict of the punisher, not the punished.  The Other is a reflection of internal cultural inconsistencies and the tensions that arise from paradox. Rather than associating the tension with the faults in their ideologies, members of a culture associate it with those that expose the inconsistencies. Morality is the attempt to anthropomorphize reality; the human mind is structured by purpose and we are unable to think of reality in any other terms but our own. To lose faith in this conception of reality is to lose reality.  Without any other alternative conceptions of reality to fall back on, the Other becomes the necessary scapegoat, the point at which cultural tensions arising from paradox can be externalized safety rather than internalized and directed toward the cultural framework. While the Medieval model was able to manage these tensions through the double substitution of the mad, the Classical model internalized its tensions to point that an exclusively religious conception of reality was a casualty of its own structure. Many of the themes of the Classical period lived on through science, the new dominant conception of reality, and past tensions continued to be externalized on the biological and the African through the guise of the rational. The Other reflects the inconsistencies of a cultural framework and can act as a clarifying agent for understanding the framework. In a sense, the exception exposes the rule, and the Other consistently is the notable exception. 
<br><br>
Works Cited
<br><br>
Fanon, Frantz. Black Skin, White Masks. N.P.: n.p., n.d. Print.
<br><br>
Foucault, Michel. 'Madness and Civilization.' N.p., n.d. Web.
<br><br>


         </q></p>";
var blog_maher = "<p> 
    (written in response to student protests against Maher) 
    <br><br>
    I find it quite worrisome how the extremes of the political spectrum are only becoming more polarized, to the point that both sides have become self-contradictory. 
<br><br>
On the conservative extreme, the goal seems to be strengthening personal liberty, but a very limited definition of it. Within this definition it is acceptable that men determine the rights women have over their bodies (e.g. the overwhelmingly male representation in the Senate and HOR that has major say over law regarding women's bodies) and dictate who can marry (e.g. homosexual marriage). By forwarding one definition of liberty, they exclude all others. 
<br><br>
On the liberal extreme, the goal seems to be empowering the disenfranchised in society, but if one has views contrary to their own standard, their own voice is discounted or their character is attacked. Tolerance can mean adamantly disagreeing with the other side but still realizing that that side has a right to their opinion. Tolerance is not respecting the content of others' views but their right to have them. Having a voice and acting on that voice are two different things. If one acts in a way that is overtly intolerant of others (e.g. hate crime), then that's one story. But if someone has bigoted beliefs they have a right to those views as long as they are tolerant of others. Right now those who have <q>bigoted</q> views are not being treated with tolerance. Prejudice is a system of double standards; in the process of trying to get rid of prejudice a new double standard has been created. In this new standard, one's right to a voice is contingent on the content of their views. The double standard is whether another's voice aligns with one's own standard. This is deeply problematic. An example of this is the Berkeley student body's response to Bill Maher's invitation to speak at UC Berkeley. It's my impression that there are two distinct issues in this situation: the role of commencement speakers at UC Berkeley and Maher's actual invitation. While many see the latter issue as the primary concern I would disagree. Regardless of whether I agree or disagree with Maher's opinions I believe he has the right to say whatever he wishes. The problem is that UC Berkeley administration evidently sees the role of the commencement speaker differently than its student body. This needs to be clarified. By disinviting Maher this is addressing the wrong issue, it would essentially be blaming Maher for having a voice and disrespecting the initial agreement that was made with him. That is his right, his right should be respected and his invitation should be respected. Instead there needs to be a discussion with the administration regarding who it chooses in the future. What should the role of commencement speaker entail? This is the question that needs to be addressed. By disinviting Maher we do not respect the contract that has been made and do not respect his right to speak. 
<br><br>
What's polarizing both sides is the same: it is self-righteousness, the inability to re-examine one's moral premises. By being so focused on one's ends, the means have begun to contradict the ends. One side is trying to support liberty by accepting only their definition of liberty, thereby excluding all other definitions. The other side is trying to get rid of prejudice through prejudice. This will mean one simple thing: neither side will achieve their objective. 
<br><br>
While I'm probably going to get a ton of flak for this comment I'm going to try something as a thought experiment: if anyone disagrees with anything in this post, please send me a message and let's have a mutually respectful discussion about it. The way I see a discussion is that both sides have an element of truth and the goal is to find a new perspective that synthesizes what's best about both sides. That means I will be wrong about many many things. My goal is self-improvement, but to self-improve I need to understand how I am wrong. To achieve my goal, I want to see things from others' perspectives. 
<br><br>
Let's have the conversation that has been long overdue.
         </p>";
var blog_civil = "<p> The United States has a long military tradition, spanning back before the Revolutionary War for Independence. Since the genesis of the country, America has almost always been at war and a sophisticated relationship between the military and the American people has evolved. One enduring aspect of this relationship originates from the Revolutionary War: America's love-hate relationship with its military leaders. Many Americans have an innate respect of their military leaders and many military leaders have become powerful political figures. The most beloved military and political figure, George Washington, championed the cause of independence and won despite the colossal odds against him. Americans, however, also have a deep distrust of absolute authority. They fear military leaders and their potential to take absolute power. This fear goes back to the Revolutionary War over a British monarch's refusal to give the colonies rights equal to Englishmen. This fear of authority has guided policies such that an elected civilian leader controls the military. Over time there has been a visible trend toward increasing civilian control of the military. This trend is apparent from examination of three military leaders: Andrew Jackson, George McClellan, and Douglas MacArthur. All three generals either refused or exceeded orders of the president. Progressively the civilian leaders gained control through specific orders, and reprimanded generals more severely for disobeying their directives. 
    <br><br>
	 Andrew Jackson acted beyond his constitutional powers and disregarded government control throughout his military career. At the start of the War of 1812, he was given command of 2,071 volunteers and was ordered to move to New Orleans to await further orders. After Jackson and his men had moved 500 miles without pay and without supplies, Secretary of War John Armstrong unexpectedly relieved him of command of his force.  Initially the force had been meant for a planned invasion of Spanish-controlled East Florida. But the invasion was canceled when Russia allied with the Spain because the US and Russia were also allied. Jackson, however, refused to leave his command and dismiss his men until he returned his troops safely home. While his act was insubordinate, it made him immensely popular with Americans and he was never punished. In the Creek War in 1813 he also went beyond his powers. The War resulted from a series of Creek Native American attacks on American border settlements. In the campaign, Jackson inflicted a devastating blow to the belligerent Creek tribes, the Red Sticks, in the Battle of Horseshoe Bend, effectively ending the Creek War.  Jackson personally orchestrated the peace treaty and war settlement so that the Creek nation would be completely cut off from the Spanish, whose influence Jackson thought responsible for the recent violence. The treaty demanded 23 million acres of land on an unconditional basis. Either the Indians agreed, or Jackson would annihilate them. Ironically, almost all the Indians chiefs present at the peace conference were allied with Jackson, since most of the antagonistic tribes had fled south to Spanish-controlled Florida.  Yet Jackson demanded that the whole Creek nation pay for what the few enemy tribes had done. As general, Jackson had no right to dictate the peace treaty, which was for the civil authorities to decide. Moreover, the treaty violated the ninth article of the Treaty of Ghent that was being negotiated at the same time, in which the United States agreed that individual Indian tribes would be treated as nations and had the right to retain their ancestral lands. By exacting 23 million acres, Jackson flagrantly violated the treaty. But like the first case, Jackson was not punished for his actions. 
	 <br><br>
	The civil administration consistently gave Jackson vague orders or no orders at all, explaining his acting beyond his powers. Following the Creek War, Jackson asked Secretary of War Armstrong to authorize the seizure of Florida not only to strike against the Indians but to ensure the future security of the area. After more than half a year Armstrong finally issued a vague reply, writing that if the Spanish <q>feed, arm, and co-operate with the British and hostile Indians, we must strike on the broad principle of self-preservation: -under other and different circumstances, we must forbear.</q>  In the meantime, Jackson took it upon himself to take Pensacola, the center of Spanish control in Florida. He sent a second letter to the new secretary of war, James Madison, explaining the reason for his action. He claimed that the Spanish at Pensacola had <q>permit[ted] the place to assume the character of a British Territory by resigning the command of the Fortresses to them [British], Permitting them to fit out an expedition against the U.S. and after its failure to return to the Town refit, and make arrangements for a second expedition. At the same time making to me a declaration that he (the Spanish Governor) had armed the Indians and send them to our Territory. Knowing at the same time that these very Indians had under the command of a British officer captured our citizens and destroyed their property within our own Territory.</q>  Once the British and hostile Creeks left Pensacola, Jackson returned the town to the Spanish. Although Jackson wound up doing exactly what the US government later ordered, he had acted on his own initiative and could have easily triggered war with Spain, a war that the civil authorities were unprepared for. 
	<br><br>
	 In a second case, the civil authorities gave extremely vague orders that could have been misconstrued. During the Seminole War in 1817, President James Monroe sent a purposefully ambiguous letter to Jackson stating: <q>Great interests are at issue, and until our course is carried through triumphantly and every species of danger to which it is exposed is settled on the most solid foundations, you ought not withdraw your active support of it.</q>  Interpreting <q>great interests</q> as the American seizure of Florida, Jackson took the letter as an invitation to wipe out the hostile Seminoles and seize Florida from Spain. Meanwhile Monroe told Secretary Calhoun expressly to write Jackson and order him to avoid confrontation with the Spanish, but Calhoun never sent the order for reasons that are unknown.  With 3,000 regulars and volunteers, and 2,000 Indian allies, Jackson terrorized the Seminoles on Spanish territory, seized the Spanish fort at St. Marks by coercive means, and captured and put to death two British subjects, Robert Ambrister and Alexander Arbuthnot, who had been helping the Seminoles.  Before taking Pensacola, Jackson sent a letter to Calhoun justifying his intended actions. Jackson claimed that the Spanish were inciting Indian violence by selling arms to belligerent tribes and that the only way permanently to stop the violence was to make the Indians dependent exclusively on the United States. The Spanish quickly surrendered Pensacola and Jackson agreed <q>under the terms of capitulation to allow the Spanish garrison to retire from the Fortress with full honors of war, transport them to Cuba, and to respect Spanish rights and property.</q>  With Spanish authority gone in Pensacola, the United States essentially had complete control over Florida. 
	 <br><br>
	Based on vague orders from Washington, Jackson had attacked both British and Spanish subjects and property, acts that could easily have elicited formal declarations of war from both Britain and Spain. The situation was saved by John Quincy Adams, who claimed that Jackson's actions had been a military necessity to rout the Seminoles. Adams also claimed that the Spanish commanders at St. Marks and Pensacola had not been doing their duty in that they were not preserving order in Spanish territory. Adams' response placated the Spanish and negotiations for the purchase of the territory began.  In the end Jackson was never seriously reprimanded. The extent of punishment was a letter written by Monroe accusing Jackson of going beyond his powers.  <br><br>
	In Jackson's era, generals in the field in many ways had powers superior to the president. Instead of reprimanding Jackson for his disobedience in refusing to relinquish his command or for exceeding his constitutional powers to conclude the Creek War Peace Treaty, the president did nothing. Not only that, instead of giving Jackson straightforward orders, the civil authorities often gave him ambiguous orders which Jackson then used for his own motives to justify politically dangerous actions, like putting to death Ambrister and Arbuthnot, both British subjects. In part, Jackson had superiority in the field because of slow communications. Naturally the government could not preside over its generals several hundred miles away with a communication system that took days or even weeks to transmit a single order. At the same time however, the government did nothing to reprimand unruly generals like Jackson who acted impulsively, and thereby risked war. 
	<br><br>
	Abraham Lincoln and George McClellan during the American Civil War demonstrate a change in civil-military relations. While Monroe had no direct control over Jackson, giving Jackson superior powers, the relationship between Lincoln and McClellan was much closer and put the president and general on a more equal footing. Initially, however, McClellan was very much given the powers of the superior. Although Lincoln made very explicit suggestions he deferred to McClellan's own course of action. It is unclear whether this treatment stemmed from Lincoln's humility and his lack of war experience, or from a belief that McClellan would be more capable with the powers of the superior. Either way, Lincoln's approach only encouraged McClellan's egotism, his disrespectful behavior towards his civil superiors, and his over-cautiousness. 
	<br><br>
By constantly deferring to McClellan, Lincoln only reinforced McClellan's feelings of superiority. Being so pampered and inflated by favorable public opinion, McClellan became obsessed with the idea that God had appointed him to his station to save the Union.  Given this state of mind, he kept all control of strategic planning and information to himself and away from his superiors. Before he became general-in-chief of the Army of the Potomac, Winfield Scott, the general-in-chief at the very beginning of the Civil War, complained bitterly about McClellan's making public information that McClellan even refused to tell him.  Similarly on January 12, 1862, in a war council that included the president and secretary of state, McClellan refused to disclose his war plans on the grounds that <q>there are many here [at the meeting] entirely incompetent to pass judgment upon them ... no plan made known to so many persons can be kept secret an hour.</q>  Instead of forcing McClellan to tell the war council, Lincoln simply asked him if he had some sort of timeline for his plan. When McClellan answered in the affirmative, Lincoln ended the war council. The following day McClellan gave a reporter of the New York Herald a three-hour briefing on his war plans. All the confidential information was then published, constituting the largest information leak of the entire war. McClellan was not reprimanded in any way.  
<br><br>
Lincoln's deference also encouraged McClellan's disrespect towards his superiors. After a conversation with Secretary of State William Seward about then general-in-chief Winfield Scott, McClellan wrote to his wife: <q>How does he [Seward] think that I can save this country when stopped by Genl Scott - I do not know whether he is a dotard or a traitor!... I am leaving nothing undone to increase our force - but that confounded old Genl always comes in the way - he is a perfect imbecile. He understands nothing, appreciates nothing &amp; is ever in my way</q>  Beyond demonstrating his disrespect of his superiors, the letter also reflects McClellan's inflated view of himself. Similarly, in his letters to his wife, he referred to Lincoln as the <q>original gorilla</q> and <q>nothing more than a well-meaning baboon.</q>  McClellan's actions spoke as loudly as his words. In one case, Lincoln, Seward, and Lincoln's personal secretary John Hay waited for an hour at McClellan's home for him to arrive. When McClellan finally came home, he immediately went to bed without meeting them.  
<br><br>
	Finally, Lincoln's deference encouraged McClellan's over-cautiousness. McClellan relied exclusively on the reports of Allen Pinkerton, the head of his intelligence department, even though Pinkerton's statistics consistently and grossly exaggerated Confederate forces.  McClellan, in his prima donna belief that he would be the savior of the Union, wanted to believe the absurd statistics for his own self-image, and by not questioning them, Lincoln seemed to be silently accepting the faulty statistics. In one letter to his wife, McClellan claimed that <q>I am here in a terrible place - the enemy have 3 to 4 times my force - the Presdt is an idiot, the old General in his dotage - they cannot or will not see the true state of affair...</q>  In fact McClellan's force always outnumbered the Confederate forces. In another case, McClellan received information that there were between 120,000 to 150,000 Confederate soldiers in northern Virginia alone and a total enemy strength of approximately 385,000 men.  In fact there were 200,000 Confederates total. As a result, McClellan perpetually fought on the defensive and refused to move his men. On January 27, 1862, after nearly three months of complete idleness, Lincoln issued the President's General War Order No. 1 directing McClellan to move the Union armies on February 22, George Washington's birthday.  McClellan's intended amphibious assault for his Peninsula Campaign then pushed things so far back that Lincoln issued the President's War Order No. 3, instructing McClellan to move by March 18.  Not only was McClellan's refusal to move the Army of the Potomac based on faulty information but it also benefited the Confederacy which gained more time to build up its army and fortify its position.
	<br><br>
	Lincoln gradually took control as it became evident what kind of military commander McClellan was. In the President's General War Order No. 2, Lincoln directed McClellan to divide the Army of the Potomac into four corps each led by a senior division commander, limiting McClellan's control over the Army of the Potomac.  Likewise, immediately before McClellan's intended Urbanna Campaign, Lincoln removed him as general-in-chief when he learned that the Confederates had moved south of the Rappahannock River, making McClellan's plan useless. Initially, McClellan's plan had been to flank the Confederates at Manassas Junction and Centreville by making an amphibious landing at Urbanna, behind enemy lines. McClellan's power was further limited after his Peninsula Campaign failed and he was completely removed from command. McClellan was then given his command again at the Battle of Antietam, his final chance to redeem himself, but was removed permanently after he first failed to pursue General Robert E. Lee's army directly following the battle and second refused to follow Lincoln's direct order to move south to Richmond to force final confrontation with Lee. 
	<br><br> 
	After McClellan, Lincoln strictly acted as commander-in-chief to his generals. He replaced his senior-generals frequently and went through another four generals until he found Ulysses S. Grant. When he did promote Grant, Lincoln reportedly said to him <q>You are not to decide, discuss or confer with any one or ask political questions; such questions the President holds in his own hands, and will submit them to no military conferences or conventions.</q> In response, Grant wrote <q>So long as I hold my present position, I do not believe I have the right to criticize the policy or orders of those above me, or give utterance to views of my own, except to authorities in Washington.</q>  After McClellan, Lincoln left no room for doubt on who made policy. 
	<br><br>	
	The evolution of civil-military relations, from Jackson to McClellan to Grant shows a steady progression to more civil control of military. From Jackson to McClellan, the change came in the form of more explicit directions from the president. While Jackson received few orders, and those that he did receive were ambiguous, McClellan received explicit suggestions from the president. As McClellan continued to refuse to listen to Lincoln's suggestions and his own plans were ineffective, Lincoln began to give explicit orders. By the time Grant appeared on the scene, there was no question of whether Lincoln was suggesting or ordering, by then Lincoln acted as the absolute superior over the general. A second change was the threat of the civil authorities punishing their generals. Jackson was never severely reprimanded for any of his actions. Initially McClellan too avoided any punishment for his misconduct. However, Lincoln slowly adjusted his policy and began to punish McClellan more and more severely until he relieved him completely. Thereafter Lincoln refused to indulge his generals and would immediately punish them (by relieving them) for failing. 
	<br><br>
The relationship between President Harry Truman and General Douglas MacArthur during the Korean War was a case of serious military opposition to civilian authority. Their disagreement stemmed from differing views on the Constitution. While Truman believed that the civil administration was in charge of the military because it was elected popularly by the people and the Constitution made him commander-and-chief of the military, MacArthur believed his military expertise allowed him to defy the civil administration if he believed his solution would be better for the people. By maintaining this interpretation, MacArthur seemed to believe that he was superior to Truman and his administration, and he constantly defied orders. 
MacArthur's treatment of the civil authorities reflected his sense of superiority. When Truman and MacArthur met at Wake Island in October of 1950 to discuss the Korean War, MacArthur greeted Truman in informal clothing, not befitting such a formal conference. Truman was deeply offended, and later said that <q>if he'd been a lieutenant in my outfit going around dressed like that, I'd have busted him so fast he wouldn't have known what happened to him.</q> Not only that, when they met, MacArthur did not salute to the President, but shook hands.  While it seemed minor, the refusal to salute reflected MacArthur's sense of superiority. <br><br>

Likewise, MacArthur also was known for expressing his views on international politics. During the occupation of Japan, Clyde A. Lewis, the head of the Veterans of Foreign Wars (VFW), asked MacArthur to write an address for the next VFW annual encampment. MacArthur sent a response in which he explicitly expressed his views on Formosa (now Taiwan), claiming the United States had to maintain control because <q>the geographic location of Formosa is such that in the hands of a power unfriendly to the United States it constitutes an enemy salient in the very center</q>  of American control of the Pacific. The timing of the address could not have been worse. Truman had just asked the United Nations to investigate the <q>Formosa question</q> in order to limit the areas of fighting in the Far East. Truman felt that <q>General MacArthur's message - which the world might mistake as an expression of American policy - contradicted this,</q>  and that he [Truman] <q>gave serious thought to relieving General MacArthur as our military field commander in the Far East.</q>  Truman immediately ordered MacArthur to <q>withdraw your [his] message for National Encampment of Veterans of Foreign Wars, because various features with respect to Formosa are in conflict with the policy of the United States and its position in the United Nations.</q>  MacArthur immediately complied with the order, but a copy was still published. <br><br>

	Unlike the previous relationships, the Truman administration gave very explicit instructions to MacArthur, which he defied. Following MacArthur's successful Inchon Landing in September of 1950 into Communist-held Korea, the Joint Chiefs ordered MacArthur to <q>conduct military operations north of the 38th Parallel</q> to complete <q>the destruction of the North Korean armed forces.</q>  There were only two major restrictions in the order: first they forbade him to fly aircraft over Sino-Russian territory, and second they allowed only South Korean troops to be used to approach the Yalu River in northern Korea, on the Korean-Chinese border.  The US government wanted to avoid Chinese intervention to keep the conflict contained to a regional theater. Truman warned MacArthur to avoid <q>military action against objectives in Chinese territory</q> on several occasions.  MacArthur however, defied these orders. Four days after seizing Pyongyang on October 24, MacArthur forged ahead toward the Yalu with the US Eighth Army of the X Corps, in direct violation of the order given to him by the Joint Chiefs.  MacArthur claimed that the South Koreans were without <q>strength and leadership.</q>  MacArthur's decision, just as the Joint Chiefs had feared, led to Chinese intervention, the failure of MacArthur's offensive, and the rout of US troops. The civil administration had given MacArthur explicit directions and he brazenly ignored the order, causing exactly what the Truman Administration wanted to avoid. 
	<br><br>
Truman eventually relieved MacArthur for insubordination after giving him straightforward orders concerning public addresses. In response to MacArthur's Veterans of Foreign Wars speech, Truman issued his December 6 Directive (1950). In it, he said that military officials could not issue public statements unless cleared first by the government to insure that the information made public is accurate and fully in accord with the policies of the United States Government, and that <q>officials overseas, including military commanders and diplomatic representatives, should ... exercise extreme caution in public statements ...clear all but routine statements with their departments, and ... refrain from direct communication on military or foreign policy with newspapers, magazines or other publicity media in the United States.</q>  Only a few months later, on March 15, 1951, MacArthur blatantly violated the directive and committed <q>a major act of sabotage.<q>  After China became involved in the Korean War, MacArthur issued a public declaration mocking the Chinese, claiming that China <q>lack[ed] the industrial capacity</q> for <q>the conduct of modern war,</q> and that China had demonstrated <q>its complete inability to accomplish by force of arms the conquest of Korea. The enemy therefore, must by now be painfully aware that a decision by the United Nations to depart from its tolerant effort to contain the war would doom Red China to the risk of imminent military collapse.</q>  MacArthur issued this declaration as Truman was coordinating peace talks with China. Not only had MacArthur misrepresented US foreign policy, but his insulting tone utterly compromised the peace talks. Later Truman wrote that <q>if I allowed him to defy the civil authorities in this manner, I myself would be violating my oath to uphold and defend the Constitution.</q>  Truman relieved MacArthur of his command for his address and replaced him with Lieut. Gen. Mathew B. Ridgway. 
<br><br>
	Compared to the previous relationships, Truman asserted even greater civil control over the military. He issued very specific orders to MacArthur giving him clear limits to his command. In contrast to previous generals, the civil authorities responded more rapidly to MacArthur's misconduct, and attempted either to correct or reprimand him. Another layer of control, Truman curbed the general's freedom of speech. With MacArthur's Veterans of Foreign Wars speech and his final address to the Chinese, he did not have the authority to make policy. Once again, with better communications, the opinions of a general like MacArthur would have been heard around the world in a day. So Truman limited his general's freedom to make public pronouncements. 
	<br><br>
	The US government is remarkable because of its great flexibility. The trend towards greater civil control of the military is an ongoing process, most recently evident in the resignation of General Stanley A. McChrystal for his staff's derogatory comments about the civil administration in June of 2010.  While the trend itself could be the result of the American love-hate relationship with their generals, technology has affected the trend. Better communications have been instrumental for the US civil authorities to assert control over their generals, especially since the scope of warfare has expanded immensely in a relatively short time, from the local wars of Jackson, to the national civil war of McClellan, to a distant global war of MacArthur. It is unclear whether the trend is based on the ability to manipulate technology for greater control, or the necessity to do so to prevent global escalation.  Or reality could be a combination of both. The continuing advancement of technology promises even greater civil control of the military. The military is becoming civilianized in a number of ways as technology becomes more sophisticated. Whole sectors of the military are now dominated by personnel who fly UAVs and other unmanned aircraft from the safety of the United States. Opposed to the traditional view of soldiers fighting hundreds or thousands of miles away, these new civilianized military personnel commute to work from home and wage war on the enemy from the office. Meanwhile in the last year in Afghanistan for first time in history more civilian contractors died than soldiers.  Not only are the civil authorities more in control of the military, but with technology the military is becoming more civilianized itself. Just as the US military began as a civilian-based militia in the Revolutionary War, it seems to be drifting back to its origin, forsaking a standing army for an army of white-collared warriors whose primary weapon is now the computer. 

         </q></q></p>";
var blog_sleep = "<p> 
    Walking down the stairs <br>
    In the dead of night 
    <br>Seeing with my feet 
    <br>Without the gift of sight<br><br>
    Knowing that the last<br>
    Could be coming soon
    <br>But uncertain when
   <br>Without the light of moon 
   <br><br>Then comes the plummet<br>
   Fall to end all falls <br>
   Only to find the ground<br>
   With my Dr. Scholls 
   <br><br>
   Walking from the stairs<br>
   In the dead of night<br>
   Experiencing with my feet
   <br>Quite a sad sore fright<br><br>
           </p>"
var blog_english = "<p> 
    (this is an essay from 2012)
    <br><br>
    
    Language is a conduit of the mind, a medium for turning ideas into an expressible form. In George Orwell's <q>Politics and the English Language,</q> he discusses the symbiotic relationship between language and thinking in society. Orwell makes the point that while language is a tool of communication, it is fluid depending on how society uses it. Conversely, he reasons that contemporary, popular language shapes how society thinks because people allow language to shape their thoughts rather than taking the time to mold language to their ideas. While language is fluid, the dynamic that Orwell outlined does not seem to be. Today societal shifts seem to be accompanied by language shifts, and vice versa. As the world becomes more interconnected, change has become exponentially faster and the changes of this decade have far surpassed those of the preceding decades. This is greatly reflected, as Orwell pointed out, in the change of language. 
    <br><br>
	The Internet and the introduction of means of instant-communication have induced a language revolution in the United States. With this technological explosion, we receive communications and subliminal messages in every shape and form and often simultaneously.  While I work on my computer, I have nearly twenty separate documents and websites up at the same time, often receiving notifications and e-mails while working, and going in and out of one thing and then another. Not only that, but on every website there are numerous commercials that advertise everything from T-shirts to movies to software while I work. In this world of ubiquitous distractions, sensory binging is an inescapable product of the information-age.  In order to survive, the information-age generation has been forced to adapt both its thinking and its language to its environment. In order to accommodate our mental-juggling a new colloquial language has developed: text-speak. 
	<br><br>
What would have been considered near-illiteracy only a decade ago is now practically a universal language, full of nuances and expressions. Text-speak is crude and simplistic and is justifiably viewed as a step in the wrong direction, but it does its job: it allows simple thoughts be conveyed efficiently. It is just one linguistic response to a changing world. But linguistic responses can also change thinking and thus the course of human history. Text-speak is so pared down and abbreviated that it can convey only very simple ideas. While this satisfies its intended purpose, it limits the ability to convey more complex thoughts. The strength of language comes in flexibility, the ability to convey a broad spectrum of meaning concisely and coherently. A flawed language has the ability to constrain the mind just as much as a good language can free it to communicate. Text-speak, unfortunately, does not fit the criteria of a flexible language. 
<br><br>
Nearly seventy years ago, Orwell reasoned that as thinking processes shape language, language equally shapes thinking. With this reasoning in mind, test-speak will invariably change our thinking processes, especially if our reliance on it increases. Text-speak is an inflexible language and is unable to convey deep thought. Logically, we can assume that if usage continues or increases, this technological generation will be constrained by its own devices, but the question is how. 
<br><br>
In the case of test-speak and texting in general, the answer is multi-faceted. Recent studies have indicated that texting has neurological effects on the brain. Among other things, evidence suggests that texting is addictive to the brain in the same way certain narcotics are. This assertion is supported by unrelated polls that show twenty percent of test subjects to be prone to hyper-texting, sending over 120 texts a day. Not only that, but there seems to be a strong correlation between hyper-texting and using cigarettes, alcohol, and other narcotics; being sexually active with several partners; and being physically violent. While it is unclear whether these behaviors are in any way dependent on hyper-texting, it is still a disturbing correlation. 
<br><br>
	As the technological revolution charges onwards, we can draw the conclusion that dependence on text-speak will only grow. Not only that, but addictive neurological effects will only increase the reliance on texting over time, thus magnifying how text-speak affects thinking processes. Text-speak is an inflexible language and if usage continues it may impede how people convey complicated thoughts. A flexible language when used correctly gives structure to abstract reasoning and allows the user to analyze information in a highly sophisticated manner more easily. We live in a world full of intricate motives and relationships and the ability to reason is universally useful and applicable. If we, as a society, begin to rely heavily on an intrinsically inflexible language, our ability to give structure to our thoughts will be greatly hindered. Ironically the product of an age founded on reasoning may fundamentally impede this society's ability to reason. 
	<br><br>

         </p>";
